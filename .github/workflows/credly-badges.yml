name: Credly Badges

on:
  workflow_dispatch:
  schedule:
    - cron: '0 7 * * *'  # daily at 07:00 UTC

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Fetch all Credly pages
        run: |
          set -euo pipefail
          BASE="https://www.credly.com/users/jason-gardner.a0afe0ad/badges.json"
          UA="Mozilla/5.0 (GitHubActions Credly Fetcher)"
          rm -f badges_page_*.json all_badges.json || true

          for page in $(seq 1 50); do
            URL="${BASE}?page=${page}"
            echo "Fetching $URL"
            code="$(curl -sS -L -A "$UA" -w '%{http_code}' -o "badges_page_${page}.json" "$URL" || true)"
            if [ "$code" != "200" ]; then
              echo "HTTP $code; stopping."
              rm -f "badges_page_${page}.json"
              break
            fi
            # stop if empty list or empty data array
            python - <<'PY'
import json, sys, pathlib
p = json.load(open(sys.argv[1]))
n = len(p) if isinstance(p, list) else len(p.get("data") or p.get("badges") or [])
print(n)
PY "badges_page_${page}.json" > count.txt
            if [ "$(cat count.txt)" = "0" ]; then
              echo "No items on page ${page}; stopping."
              rm -f "badges_page_${page}.json"
              break
            fi
          done

          # Combine pages
          python - <<'PY'
import json, glob
all_items = []
for path in sorted(glob.glob("badges_page_*.json")):
    p = json.load(open(path))
    if isinstance(p, list):
        all_items.extend(p)
    else:
        all_items.extend(p.get("data") or p.get("badges") or [])
json.dump(all_items, open("all_badges.json","w"))
print(f"Total badges: {len(all_items)}")
PY

      - name: Render badges into READ
